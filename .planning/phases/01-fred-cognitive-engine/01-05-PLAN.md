# Plan 01-05: FRED API Endpoints

**Status:** COMPLETED
**Phase:** 01 - FRED Cognitive Engine Foundation
**Depends On:** 01-02, 01-03, 01-04 (needs state machine, scoring, and AI client)
**Estimated Complexity:** Medium

---

## Objective

Create the FRED API endpoints for external access: /api/fred/analyze, /api/fred/decide, /api/fred/memory, /api/fred/chat.

---

## Context

These endpoints expose FRED's cognitive capabilities to the frontend and potentially mobile apps (API-first architecture). Each endpoint:
- Requires authentication via Supabase
- Uses the state machine for processing
- Includes rate limiting
- Returns structured JSON responses
- Logs all requests for observability

---

## Implementation Summary

### Created Endpoints

1. **POST /api/fred/analyze** (`app/api/fred/analyze/route.ts`)
   - Analyzes messages using FRED's cognitive framework
   - Returns intent, entities, mental models, synthesis, and response
   - Rate limited (20 req/min for free tier)

2. **POST /api/fred/decide** (`app/api/fred/decide/route.ts`)
   - Provides scored decision recommendations using 7-factor scoring
   - Auto-detects decision type or accepts explicit type
   - Supports calibration tracking for prediction accuracy
   - Returns composite scores, factor breakdown, and FRED analysis

3. **Memory Endpoints** (`app/api/fred/memory/route.ts`)
   - **GET** - Retrieve memories (episodes, facts, decisions, or semantic search)
   - **POST** - Store new facts or episodes with optional embedding generation
   - **DELETE** - Remove facts from semantic memory

4. **POST /api/fred/chat** (`app/api/fred/chat/route.ts`)
   - Streaming chat with FRED using Server-Sent Events
   - Non-streaming mode available via `stream: false`
   - Automatic conversation storage in episodic memory

### Rate Limiting Middleware

**File:** `lib/api/rate-limit.ts`

- In-memory sliding window rate limiter
- Tiered limits: free (20/min), pro (100/min), studio (500/min), unlimited
- Rate limit headers in responses (X-RateLimit-Limit, X-RateLimit-Remaining, etc.)
- 429 responses when limit exceeded with Retry-After header

---

## Testing

### Unit Tests (app/api/fred/__tests__/fred-api.test.ts)
- [x] Test request validation (400 for invalid input)
- [x] Test authentication requirement (401 for unauthenticated)
- [x] Test successful analyze flow
- [x] Test successful decide flow with scoring
- [x] Test memory CRUD operations
- [x] Test streaming and non-streaming chat

### Rate Limit Tests (lib/api/__tests__/rate-limit.test.ts)
- [x] Test under-limit requests allowed
- [x] Test over-limit requests blocked
- [x] Test per-identifier tracking
- [x] Test 429 response generation
- [x] Test tier configuration

### All Tests Pass
- 21 FRED API tests
- 10 rate limit tests
- 357 total tests passing

---

## Verification

- [x] All endpoints require authentication (requireAuth)
- [x] Request validation catches bad input (Zod schemas)
- [x] Responses are properly structured (success, data, meta)
- [x] Errors return appropriate status codes (400, 401, 429, 500)
- [x] Rate limiting protects endpoints
- [x] Streaming works for chat endpoint (SSE)
- [x] Memory search returns relevant results (embedding-based)
- [x] Decision scoring uses 7-factor engine
- [x] Calibration tracking supported for decision accuracy

---

## API Documentation

### POST /api/fred/analyze
Analyze a message/question using FRED's cognitive framework.

**Request:**
```json
{
  "message": "Should I hire a VP of Engineering?",
  "context": {
    "startupName": "TestCo",
    "stage": "seed",
    "industry": "SaaS"
  },
  "sessionId": "optional-uuid"
}
```

**Response:**
```json
{
  "success": true,
  "sessionId": "uuid",
  "analysis": {
    "intent": "decision_request",
    "confidence": 0.9,
    "entities": [],
    "clarificationNeeded": []
  },
  "mentalModels": [...],
  "synthesis": {...},
  "response": {...},
  "meta": { "latencyMs": 150, "finalState": "complete" }
}
```

### POST /api/fred/decide
Get a scored decision recommendation using 7-factor scoring.

**Request:**
```json
{
  "decision": "Should we raise a Series A now or wait 6 months?",
  "decisionType": "fundraising", // optional, auto-detected
  "context": {
    "startupName": "TestCo",
    "stage": "seed",
    "industry": "SaaS"
  },
  "trackCalibration": true
}
```

**Response:**
```json
{
  "success": true,
  "decisionId": "uuid",
  "decisionType": "fundraising",
  "scores": {
    "composite": 75,
    "confidence": 0.8,
    "recommendation": "proceed",
    "uncertaintyRange": { "low": 70, "high": 80 },
    "factors": {
      "strategicAlignment": { "value": 0.8, "weight": 0.2, "reasoning": "..." },
      ...
    }
  },
  "analysis": {...},
  "response": {...}
}
```

### GET /api/fred/memory
Retrieve user's stored memories.

**Query Parameters:**
- `type`: "episodes" | "facts" | "decisions" | "search"
- `category`: semantic category for facts
- `query`: search query (required for type=search)
- `limit`: number of results (default 10)

### POST /api/fred/memory
Store a new fact or episode.

**Request (fact):**
```json
{
  "type": "fact",
  "category": "startup_facts",
  "key": "company_name",
  "value": { "name": "TestCo" },
  "generateEmbedding": true
}
```

### DELETE /api/fred/memory
Remove a fact from semantic memory.

**Request:**
```json
{
  "category": "startup_facts",
  "key": "old_fact"
}
```

### POST /api/fred/chat
Stream a conversational response from FRED.

**Request:**
```json
{
  "message": "Hello FRED",
  "context": {...},
  "sessionId": "optional-uuid",
  "stream": true,
  "storeInMemory": true
}
```

**SSE Events:**
- `connected` - Initial connection
- `state` - State machine transitions
- `analysis` - Input analysis
- `models` - Mental models applied
- `synthesis` - Synthesis results
- `response` - Final response
- `done` - Stream complete
- `error` - Error occurred

---

*Plan created: 2026-02-05*
*Completed: 2026-02-05*
