---
phase: 63-fred-intelligence-upgrade
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - lib/db/migrations/063_memory_vector_search_rpcs.sql
  - lib/fred/actors/load-memory.ts
  - lib/db/fred-memory.ts
  - app/api/fred/chat/route.ts
autonomous: true

must_haves:
  truths:
    - "FRED retrieves semantically relevant past conversations, not just the most recent ones"
    - "New episodes are stored with embeddings for future vector search"
    - "Vector search RPCs exist in the database and are called by the memory layer"
  artifacts:
    - path: "lib/db/migrations/063_memory_vector_search_rpcs.sql"
      provides: "pgvector RPC functions for episodic and semantic memory search"
      contains: "search_episodic_memory"
    - path: "lib/fred/actors/load-memory.ts"
      provides: "Embedding-based memory retrieval merged with recency"
      contains: "generateEmbedding"
    - path: "lib/db/fred-memory.ts"
      provides: "Async embedding generation on episode store"
      contains: "generateEmbedding"
  key_links:
    - from: "lib/fred/actors/load-memory.ts"
      to: "lib/db/fred-memory.ts"
      via: "searchEpisodesByEmbedding call"
      pattern: "searchEpisodesByEmbedding"
    - from: "app/api/fred/chat/route.ts"
      to: "lib/fred/actors/load-memory.ts"
      via: "currentMessage parameter passed through fredService"
      pattern: "currentMessage|message"
    - from: "lib/db/fred-memory.ts"
      to: "lib/ai/fred-client.ts"
      via: "generateEmbedding for async embedding on store"
      pattern: "generateEmbedding"
---

<objective>
Upgrade FRED's memory retrieval from recency-only to embedding-based semantic search, and ensure new episodes are stored with embeddings.

Purpose: Currently loadMemoryActor fetches episodes by `created_at DESC` regardless of relevance. Episodic memories are stored without embeddings, making pgvector search impossible. This plan creates the database RPCs, adds embedding generation on store, and enhances the load-memory actor to use semantic similarity alongside recency.

Output: Working embedding-based memory retrieval that finds contextually relevant past conversations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/63-fred-intelligence-upgrade/63-RESEARCH.md

@lib/fred/actors/load-memory.ts
@lib/db/fred-memory.ts
@lib/ai/fred-client.ts
@app/api/fred/chat/route.ts
@lib/fred/service.ts
@lib/fred/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pgvector RPC functions and add async embedding on episode store</name>
  <files>
    lib/db/migrations/063_memory_vector_search_rpcs.sql
    lib/db/fred-memory.ts
  </files>
  <action>
    1. Create migration `lib/db/migrations/063_memory_vector_search_rpcs.sql` with two RPC functions:
       - `search_episodic_memory(query_embedding vector(1536), match_user_id uuid, match_threshold float DEFAULT 0.7, match_count int DEFAULT 5)` — returns episodic memory rows with similarity score, filters by `embedding IS NOT NULL` and `1 - (embedding <=> query_embedding) > match_threshold`, ordered by cosine distance, limited to match_count.
       - `search_semantic_memory(query_embedding vector(1536), match_user_id uuid, match_threshold float DEFAULT 0.7, match_count int DEFAULT 5, match_category text DEFAULT NULL)` — same pattern for semantic memory, with optional category filter.
       - Use `CREATE OR REPLACE FUNCTION` so it's safe to re-run.
       - Use `LANGUAGE plpgsql` and `SECURITY DEFINER` for RLS bypass (service role context).
       - Reference the exact table and column names from the existing `fred_episodic_memory` and `fred_semantic_memory` tables.

    2. In `lib/db/fred-memory.ts`, modify `storeEpisode()` to generate an embedding asynchronously (fire-and-forget) after the insert:
       - After the successful insert, if the content has a `content` string field (role=user or role=assistant), fire-and-forget an async function that:
         a. Imports `generateEmbedding` from `@/lib/ai/fred-client`
         b. Generates embedding for the content string (truncated to 8000 chars to stay within embedding model limits)
         c. Updates the row with `supabase.from('fred_episodic_memory').update({ embedding }).eq('id', insertedId)`
         d. Wraps everything in try/catch and logs warnings on failure (never throws)
       - Do NOT make the original storeEpisode await the embedding — it must remain fast.
       - Add a helper function `fireEmbeddingGeneration(episodeId: string, text: string): void` that does the fire-and-forget work.
  </action>
  <verify>
    - `cat lib/db/migrations/063_memory_vector_search_rpcs.sql` shows valid SQL with both RPC functions
    - `grep -n "fireEmbeddingGeneration\|generateEmbedding" lib/db/fred-memory.ts` shows the async embedding generation in storeEpisode
    - `npx tsc --noEmit` passes (no type errors)
  </verify>
  <done>
    Migration file creates search_episodic_memory and search_semantic_memory RPCs. storeEpisode fires async embedding generation after insert.
  </done>
</task>

<task type="auto">
  <name>Task 2: Enhance loadMemoryActor with embedding-based retrieval</name>
  <files>
    lib/fred/actors/load-memory.ts
    app/api/fred/chat/route.ts
  </files>
  <action>
    1. In `lib/fred/actors/load-memory.ts`:
       - Add a new parameter `currentMessage?: string` to the function signature (after preloadedFacts).
       - When `config.loadEpisodic` is true AND `currentMessage` is provided:
         a. Import `generateEmbedding` from `@/lib/ai/fred-client`
         b. Generate embedding for the current message (wrap in try/catch, fall back to recency-only on failure)
         c. Import `searchEpisodesByEmbedding` and `searchFactsByEmbedding` from `@/lib/db/fred-memory`
         d. Run in parallel alongside the existing recency query:
            - `searchEpisodesByEmbedding(userId, embedding, { limit: 5, similarityThreshold: 0.75 })`
            - `searchFactsByEmbedding(userId, embedding, { limit: 5, similarityThreshold: 0.7 })`
         e. Merge and deduplicate episodes: combine recent episodes with embedding-matched episodes using a Set of IDs, then slice to `config.maxEpisodicItems`
         f. For facts: merge preloaded facts with embedding-matched facts, deduplicate by `category+key` composite key
       - If `currentMessage` is not provided OR embedding generation fails, keep the existing recency-only behavior unchanged.

    2. In `app/api/fred/chat/route.ts`:
       - The `createFredService` call currently does not pass the user's message for memory loading. Find where the service is created (around line 495) and add `currentMessage: message` to the service options.
       - In `lib/fred/service.ts`, thread the `currentMessage` parameter through to the `loadMemoryActor` call. Check how `createFredService` passes options to the machine — add `currentMessage` to the service config, and pass it through to loadMemoryActor in the machine's invoke.
       - The exact threading path depends on how service.ts calls loadMemoryActor — read the file to trace the flow and wire it through appropriately.

    IMPORTANT: Do NOT break the existing recency-only behavior. Embedding retrieval is additive. If any part fails, fall back to the existing behavior silently.
  </action>
  <verify>
    - `grep -n "currentMessage\|searchEpisodesByEmbedding\|searchFactsByEmbedding" lib/fred/actors/load-memory.ts` shows embedding search wired in
    - `grep -n "currentMessage" lib/fred/service.ts app/api/fred/chat/route.ts` shows the message being threaded through
    - `npx tsc --noEmit` passes
    - `npm test -- --passWithNoTests` passes (no regressions)
  </verify>
  <done>
    loadMemoryActor accepts currentMessage, generates embedding, runs parallel recency + similarity search, merges and deduplicates results. Chat route threads user message through to memory loading. Embedding failures fall back silently to recency-only.
  </done>
</task>

</tasks>

<verification>
- TypeScript compiles without errors: `npx tsc --noEmit`
- Existing tests pass: `npm test -- --passWithNoTests`
- Migration file is valid SQL
- storeEpisode has fire-and-forget embedding generation
- loadMemoryActor combines recency + similarity search
- Chat route passes currentMessage through to memory loading
- No breaking changes to existing behavior
</verification>

<success_criteria>
1. New episodes get embeddings generated asynchronously after storage
2. Memory retrieval uses embedding similarity (when available) merged with recency
3. Chat route threads user message to enable embedding-based retrieval
4. All existing functionality preserved — embedding failures fall back silently
</success_criteria>

<output>
After completion, create `.planning/phases/63-fred-intelligence-upgrade/63-01-SUMMARY.md`
</output>
