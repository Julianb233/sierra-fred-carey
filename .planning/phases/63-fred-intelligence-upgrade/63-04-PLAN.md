---
phase: 63-fred-intelligence-upgrade
plan: 04
type: execute
wave: 2
depends_on: ["63-01"]
files_modified:
  - lib/fred/tools/content-recommender.ts
  - lib/fred/tools/provider-finder.ts
  - lib/fred/tools/memory-search.ts
  - lib/fred/tools/index.ts
  - lib/fred/actors/decide.ts
autonomous: true

must_haves:
  truths:
    - "FRED can invoke AI tools during response generation"
    - "Content recommendation tool returns structured 'coming soon' responses"
    - "Provider finder tool returns structured 'coming soon' responses"
    - "Memory search tool retrieves relevant past conversations on demand"
  artifacts:
    - path: "lib/fred/tools/content-recommender.ts"
      provides: "Content recommendation tool stub for Phase 66/67"
      exports: ["recommendContentTool"]
    - path: "lib/fred/tools/provider-finder.ts"
      provides: "Provider finder tool stub for Phase 68/69"
      exports: ["findProviderTool"]
    - path: "lib/fred/tools/memory-search.ts"
      provides: "Self-retrieval memory search tool"
      exports: ["memorySearchTool"]
    - path: "lib/fred/tools/index.ts"
      provides: "Tool registry barrel export"
      exports: ["fredTools"]
    - path: "lib/fred/actors/decide.ts"
      provides: "Tool-enabled LLM generation"
      contains: "tools"
  key_links:
    - from: "lib/fred/actors/decide.ts"
      to: "lib/fred/tools/index.ts"
      via: "import fredTools, pass to generate()"
      pattern: "fredTools"
    - from: "lib/fred/tools/memory-search.ts"
      to: "lib/db/fred-memory.ts"
      via: "searchEpisodesByEmbedding for on-demand memory retrieval"
      pattern: "searchEpisodesByEmbedding"
---

<objective>
Create AI tool definitions using Vercel AI SDK tool() and wire them into FRED's response generation.

Purpose: FRED currently has no tool-calling capability. Phases 66-69 need content recommendation and provider finding. A memory search tool allows FRED to proactively retrieve past conversations when needed. This plan creates the tool infrastructure with stubs for future features and a working memory search tool.

Output: Tool definitions registered and callable during LLM response generation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/63-fred-intelligence-upgrade/63-RESEARCH.md
@.planning/phases/63-fred-intelligence-upgrade/63-01-SUMMARY.md

@lib/fred/actors/decide.ts
@lib/ai/fred-client.ts
@lib/db/fred-memory.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create tool definitions</name>
  <files>
    lib/fred/tools/content-recommender.ts
    lib/fred/tools/provider-finder.ts
    lib/fred/tools/memory-search.ts
    lib/fred/tools/index.ts
  </files>
  <action>
    1. Create `lib/fred/tools/content-recommender.ts`:
       - Import `tool` from "ai" and `z` from "zod"
       - Export `recommendContentTool` using `tool()`:
         - description: "Search the Sahara content library for courses, articles, or videos relevant to the founder's current situation. Use when a founder asks about learning resources, wants to study a topic, or needs educational content."
         - parameters: z.object with:
           - query: z.string().describe("What the founder wants to learn about")
           - stage: z.enum(["idea", "pre-seed", "seed", "series-a", "growth"]).optional().describe("Startup stage for relevance filtering")
           - format: z.enum(["video", "article", "course", "any"]).default("any").describe("Preferred content format")
         - execute: async function that returns `{ status: "coming_soon" as const, query, message: "Content library is being built. Based on your question about \"${query}\", I'll guide you directly.", suggestedTopics: [] }`

    2. Create `lib/fred/tools/provider-finder.ts`:
       - Export `findProviderTool` using `tool()`:
         - description: "Search the Sahara service marketplace for providers who can help the founder with professional services. Use when a founder needs legal, accounting, design, development, or marketing help."
         - parameters: z.object with:
           - serviceType: z.string().describe("Type of service needed (e.g., legal, accounting, design)")
           - budget: z.enum(["low", "medium", "high", "unknown"]).default("unknown")
           - urgency: z.enum(["low", "medium", "high"]).default("medium")
         - execute: async function that returns `{ status: "coming_soon" as const, serviceType, message: "Service marketplace is being built. I can help you think through what to look for in a ${serviceType} provider.", suggestedQuestions: ["What specific ${serviceType} tasks do you need help with?", "What's your timeline?"] }`

    3. Create `lib/fred/tools/memory-search.ts`:
       - Import `tool` from "ai", `z` from "zod"
       - Import `generateEmbedding` from `@/lib/ai/fred-client`
       - Import `searchEpisodesByEmbedding` from `@/lib/db/fred-memory`
       - Export `createMemorySearchTool(userId: string)` — a factory function that returns a tool bound to the current user:
         - description: "Search your conversation history with this founder to recall what was previously discussed. Use when the founder references a past conversation, asks 'remember when we talked about...', or when you need context about prior decisions."
         - parameters: z.object with:
           - query: z.string().describe("What to search for in past conversations")
           - limit: z.number().min(1).max(10).default(5).describe("Number of results")
         - execute: async function that:
           a. Generates embedding for the query using `generateEmbedding(query)`
           b. Calls `searchEpisodesByEmbedding(userId, embedding, { limit, similarityThreshold: 0.65 })`
           c. Maps results to `{ summary: episode.content.content || JSON.stringify(episode.content), date: episode.createdAt.toISOString(), relevance: episode.similarity }`
           d. Returns `{ results, count: results.length }`
           e. On any error, returns `{ results: [], count: 0, error: "Memory search temporarily unavailable" }`

    4. Create `lib/fred/tools/index.ts`:
       - Import all three tools
       - Export a function `getFredTools(userId: string)` that returns an object of all tools:
         ```
         export function getFredTools(userId: string) {
           return {
             recommendContent: recommendContentTool,
             findProvider: findProviderTool,
             searchMemory: createMemorySearchTool(userId),
           };
         }
         ```
       - Also export the individual tools for testing.
  </action>
  <verify>
    - `ls lib/fred/tools/` shows content-recommender.ts, provider-finder.ts, memory-search.ts, index.ts
    - `npx tsc --noEmit` passes
    - `grep -n "tool(" lib/fred/tools/*.ts` shows Vercel AI SDK tool() usage in all three files
  </verify>
  <done>
    Three tool definitions created: content recommender (stub), provider finder (stub), memory search (working). All use Vercel AI SDK tool() with Zod parameter schemas. Barrel export provides getFredTools(userId) factory.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire tools into the decide actor's LLM generation</name>
  <files>lib/fred/actors/decide.ts</files>
  <action>
    1. Read `lib/ai/fred-client.ts` to understand how `generate()` works and whether it supports a `tools` option. The Vercel AI SDK `generateText()` (which `generate()` likely wraps) accepts a `tools` parameter.

    2. In `lib/fred/actors/decide.ts`:
       - Add `userId?: string` to the `decideActor` function signature (after conversationState).
       - Import `getFredTools` from `@/lib/fred/tools`
       - In the `generateWithLLM()` function (private function around line 277):
         - Add `userId?: string` parameter
         - If userId is provided, get tools: `const tools = userId ? getFredTools(userId) : undefined`
         - Check how `generate()` from fred-client.ts handles the tools parameter. If generate() wraps `generateText()` from the "ai" package, it should accept tools directly. If not, you may need to:
           a. Either modify generate() in fred-client.ts to accept and pass through a `tools` option
           b. Or import `generateText` directly from "ai" in decide.ts for tool-enabled calls
         - The preferred approach is (a): add `tools` to generate()'s options and pass through to generateText(). Check the existing generate() signature in fred-client.ts.
         - Pass tools to the generate call. When tools are present, also set `maxSteps: 3` (allows the LLM to call tools and then continue generating).

    3. Thread userId from `decideActor()` down to `generateWithLLM()`:
       - `buildResponseContent()` already receives some params — add userId
       - `generateWithLLM()` gets userId and passes tools to generate()

    4. Thread userId into decideActor from the caller:
       - Check `lib/fred/machine.ts` or wherever `decideActor` is invoked
       - The machine should have `userId` in its context — pass it through to decideActor
       - Read the machine file to understand how actors are invoked and how to pass the userId

    IMPORTANT: If generate() in fred-client.ts needs modification to accept tools, that's acceptable. Add `tools?: Record<string, unknown>` to the options and pass it through to the underlying generateText() call. Keep changes minimal.

    IMPORTANT: Tool results should be handled transparently. The Vercel AI SDK handles tool call/response cycles automatically with maxSteps. The final text output includes the tool results naturally.
  </action>
  <verify>
    - `grep -n "getFredTools\|fredTools\|tools" lib/fred/actors/decide.ts` shows tools imported and used
    - `npx tsc --noEmit` passes
    - `npm test -- --passWithNoTests` passes
  </verify>
  <done>
    decideActor accepts userId, gets tools from getFredTools, passes them to generate(). LLM can now invoke content recommender, provider finder, and memory search during response generation. maxSteps: 3 allows multi-step tool use.
  </done>
</task>

</tasks>

<verification>
- TypeScript compiles without errors: `npx tsc --noEmit`
- Existing tests pass: `npm test -- --passWithNoTests`
- Tool definitions use Vercel AI SDK tool() with Zod schemas
- decide.ts passes tools to generate() call
- Memory search tool can find relevant past conversations
- Content and provider tools return structured "coming soon" responses
</verification>

<success_criteria>
1. Three tool files exist with proper Vercel AI SDK tool() definitions
2. getFredTools(userId) returns all tools bound to the user
3. decideActor threads userId to generate() with tools
4. LLM can call tools during response generation (maxSteps: 3)
5. Tool failures are non-blocking (try/catch with graceful fallback)
</success_criteria>

<output>
After completion, create `.planning/phases/63-fred-intelligence-upgrade/63-04-SUMMARY.md`
</output>
