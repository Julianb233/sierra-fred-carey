---
phase: 34-system-prompt-overhaul
plan: 03
type: execute
wave: 2
depends_on: ["34-01", "34-02"]
files_modified:
  - lib/ai/__tests__/prompts.test.ts
  - lib/fred/__tests__/context-builder.test.ts
autonomous: true

must_haves:
  truths:
    - "System prompt contains all 11 Operating Bible principles and all 4 regression trigger protections"
    - "buildSystemPrompt replaces {{FOUNDER_CONTEXT}} placeholder correctly for both empty and populated context"
    - "buildContextBlock produces valid output for empty profiles, partial profiles, full profiles, and first-conversation handoff states"
    - "getFredGreeting uses canonical opening prompts from the Operating Bible Appendix"
    - "All tests pass via npx vitest run"
  artifacts:
    - path: "lib/ai/__tests__/prompts.test.ts"
      provides: "Prompt regression tests and builder function tests"
      min_lines: 100
    - path: "lib/fred/__tests__/context-builder.test.ts"
      provides: "Context builder unit tests"
      min_lines: 80
  key_links:
    - from: "lib/ai/__tests__/prompts.test.ts"
      to: "lib/ai/prompts.ts"
      via: "import"
      pattern: "import.*from.*prompts"
    - from: "lib/fred/__tests__/context-builder.test.ts"
      to: "lib/fred/context-builder.ts"
      via: "import"
      pattern: "import.*from.*context-builder"
---

<objective>
Add regression tests for the Phase 34 system prompt overhaul and context builder.

Purpose: The system prompt is the foundation for ALL v4.0 work (Phases 35-46 depend on it). Without tests, future changes could silently break Operating Bible compliance. The code review (34-CODE-REVIEW.md) and test results (34-TEST-RESULTS.md) both recommend these tests.

Output: Two test files that validate prompt correctness, builder function behavior, and regression trigger protections.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/OPERATING-BIBLE.md
@.planning/phases/34-system-prompt-overhaul/34-CODE-REVIEW.md
@.planning/phases/34-system-prompt-overhaul/34-TEST-RESULTS.md
@lib/ai/prompts.ts
@lib/fred/context-builder.ts
@lib/fred-brain.ts
@vitest.config.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create prompt regression tests</name>
  <files>lib/ai/__tests__/prompts.test.ts</files>
  <action>
Create a vitest test file that validates the system prompt against the Operating Bible. Use `describe`/`it` blocks with `vi` from vitest. Import directly from `@/lib/ai/prompts` -- the functions are pure (no DB, no network), so no mocking needed for prompt tests.

Tests to write:

**Group 1: FRED_CAREY_SYSTEM_PROMPT content (Operating Bible Section 20 -- all 11 principles)**

For each of the 11 Operating Principles, write an `it` test that asserts the prompt contains the key phrase. Use `expect(FRED_CAREY_SYSTEM_PROMPT).toContain(...)` or `.toMatch(...)`:

1. "Reframe before prescribe" -- contains "Reframe before prescribe" or "Never answer the surface question"
2. "Startup Reality Lens" -- contains "Feasibility" AND "Economics" AND "Demand" AND "Distribution" AND "Timing"
3. "Decision Sequencing Rule" -- contains "Never optimize downstream artifacts"
4. "Evidence > Narrative" -- contains "Narrative is earned by proof"
5. "Capital is a tool" -- contains "Do not encourage fundraising by default"
6. "Encourage without flattery" -- contains /no.*great idea.*language/i
7. "Diagnose silently" -- contains "diagnose silently" (case-insensitive)
8. "Intake before scoring" -- contains "Never score" AND "without" AND "gathering sufficient data"
9. "Decks are optional" -- contains "Do not ask for a pitch deck by default"
10. "Weekly check-ins" -- contains "Invite weekly check-ins only when"
11. "Founder wellbeing" -- contains "normalize" AND "practical"
12. "Not an agent" -- contains "NOT an agent" or "not an agent"

**Group 2: Regression triggers (Operating Bible Section 17.3)**

Write 4 tests, one for each regression trigger:
1. "Never asks founders to choose diagnostics" -- prompt contains "diagnose silently" or "Founders do not choose diagnostics"
2. "Never scores without intake" -- prompt contains "Never score without"
3. "Never encourages fundraising by default" -- prompt contains "Do not encourage fundraising by default"
4. "Never jumps to downstream artifacts" -- prompt contains "Never optimize downstream artifacts"

**Group 3: Universal Entry Flow (Operating Bible Section 5)**

1. Prompt contains "What are you building?"
2. Prompt contains "Who is it for?"
3. Prompt contains "What are you trying to accomplish right now?"
4. Prompt contains "Do NOT mention" (scores, assessments, etc.)
5. Prompt contains "Silent Diagnosis" section

**Group 4: buildSystemPrompt function**

1. `buildSystemPrompt("")` removes the `{{FOUNDER_CONTEXT}}` placeholder entirely
2. `buildSystemPrompt("")` does NOT contain the literal string "{{FOUNDER_CONTEXT}}"
3. `buildSystemPrompt("## FOUNDER SNAPSHOT\n**Stage:** Seed")` replaces placeholder with the context
4. `buildSystemPrompt("## FOUNDER SNAPSHOT\n**Stage:** Seed")` contains "**Stage:** Seed"

**Group 5: getPromptForTopic function**

1. `getPromptForTopic("fundraising")` contains "Investor Lens" (the fundraising overlay)
2. `getPromptForTopic("positioning")` contains "Positioning Readiness"
3. `getPromptForTopic("strategy")` contains "9-Step Startup Process"
4. All topic prompts do NOT contain literal `{{FOUNDER_CONTEXT}}`

**Group 6: getFredGreeting function**

1. `getFredGreeting()` returns a string (no errors)
2. The greeting contains at least one of: "What are you building", "What's the real bottleneck", "If we fixed one thing"
3. `getFredGreeting({ name: "TestCo", stage: "seed" })` includes "TestCo"

**Group 7: buildTopicPrompt function**

1. `buildTopicPrompt("fundraising", "")` works and does not contain `{{FOUNDER_CONTEXT}}`
2. `buildTopicPrompt("mindset", "## SNAPSHOT\nStage: Idea")` contains both the mindset overlay and "Stage: Idea"

**Group 8: Coaching overlays completeness**

1. COACHING_PROMPTS has keys: fundraising, pitchReview, strategy, positioning, mindset
2. Each overlay contains "Next 3" (referencing Next 3 Actions output standard) OR the overlay's specific framework name

**Group 9: buildStepGuidanceBlock function**

1. Returns empty string for an invalid step
2. Returns a string containing "CURRENT PROCESS POSITION" for a valid step
3. Includes "Do NOT advance" for a valid step
4. Includes validated steps when passed step statuses with validated entries
  </action>
  <verify>
Run: `npx vitest run lib/ai/__tests__/prompts.test.ts`
All tests pass. No compilation errors.
  </verify>
  <done>
All prompt regression tests pass. The test file covers Operating Bible compliance (11 principles, 4 regression triggers, entry flow), builder functions (buildSystemPrompt, getPromptForTopic, getFredGreeting, buildTopicPrompt, buildStepGuidanceBlock), and coaching overlay completeness.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create context builder unit tests</name>
  <files>lib/fred/__tests__/context-builder.test.ts</files>
  <action>
Create a vitest test file that validates the context builder functions. The public API is `buildFounderContext(userId, hasPersistentMemory)` which hits the database, so we need to mock the database calls.

Mock strategy:
- Mock `@/lib/supabase/server` to return a fake supabase client
- Mock `@/lib/db/fred-memory` to return fake facts
- Mock `@/lib/db/conversation-state` to return fake state
- Mock `@/lib/ai/guards/prompt-guard` to pass through (or mock `sanitizeUserInput` to return input as-is)

Use `vi.mock(...)` for module mocking. The internal functions (buildContextBlock, loadFounderProfile, etc.) are NOT exported, so we test through the public `buildFounderContext` function.

Tests to write:

**Group 1: Empty profile (no data)**

1. When profile query returns null/error and no semantic facts exist and NOT first conversation, `buildFounderContext` returns empty string
2. When profile query returns null but IS first conversation, returns a string containing "FIRST CONVERSATION" and "Universal Entry Flow" or "no onboarding data"

**Group 2: Partial profile**

1. When profile has only name and stage, output contains both but NOT "undefined" or "N/A"
2. When profile has challenges array, output contains "Current Challenges"
3. Missing optional fields (teamSize, fundingHistory, runway) do NOT appear in output

**Group 3: Full profile**

1. When profile has all fields populated, output contains "FOUNDER SNAPSHOT"
2. Output contains name, stage, industry, revenue, team size, funding
3. Output does NOT contain `{{FOUNDER_CONTEXT}}` literal

**Group 4: First conversation after onboarding**

1. When `onboarding_completed: true` and this is first conversation, output contains "HANDOFF: FIRST CONVERSATION AFTER ONBOARDING"
2. Output contains "Do NOT re-ask"
3. Output contains "Go deeper"

**Group 5: First conversation without onboarding**

1. When `onboarding_completed: false` and first conversation, output contains "FIRST CONVERSATION (NO ONBOARDING DATA)"
2. Output contains "Universal Entry Flow" or "What are you building"

**Group 6: Returning user**

1. When NOT first conversation and profile exists, output contains "Use this snapshot to personalize"

**Group 7: Enrichment data**

1. When enrichmentData has revenueHint and profile has no revenue_range, output contains "Revenue mentioned"
2. When enrichmentData has competitorsMentioned, output contains "Competitors mentioned"

**Group 8: Error handling**

1. When supabase query throws, `buildFounderContext` returns empty string (graceful fallback)
2. When semantic memory load throws, returns profile-only context (no crash)

**Group 9: Sanitization**

1. Mock sanitizeUserInput to track calls. When enrichment data contains user text, sanitize is called on it. Verify by checking the mock was called.

Important implementation notes:
- The supabase mock should return `{ data: {...}, error: null }` for the `.from("profiles").select(...).eq(...).single()` chain
- Use `vi.hoisted` or top-level `vi.mock` for module mocking
- The `buildFounderContext` function is async, so all tests should be async
- Mock the conversation state module's `getOrCreateConversationState` to avoid DB calls from `checkIsFirstConversation` -- OR mock the supabase client to handle the `fred_conversation_state` table query
- The function also calls `loadProgressContext` which dynamically imports `conversation-state`, mock that too
  </action>
  <verify>
Run: `npx vitest run lib/fred/__tests__/context-builder.test.ts`
All tests pass. No compilation errors.
  </verify>
  <done>
All context builder tests pass. The test file covers empty profiles, partial profiles, full profiles, first conversation handoff states, enrichment data injection, error handling, and sanitization verification.
  </done>
</task>

</tasks>

<verification>
- [ ] `npx vitest run lib/ai/__tests__/prompts.test.ts` -- all tests pass
- [ ] `npx vitest run lib/fred/__tests__/context-builder.test.ts` -- all tests pass
- [ ] `npx vitest run` -- full test suite passes (no regressions from new tests)
- [ ] `npx tsc --noEmit` -- no TypeScript errors
- [ ] Prompt tests validate all 11 Operating Bible principles
- [ ] Prompt tests validate all 4 regression triggers
- [ ] Context builder tests cover empty, partial, full, first-conversation, and error states
</verification>

<success_criteria>
1. All prompt regression tests pass and validate that FRED_CAREY_SYSTEM_PROMPT contains all 11 Operating Bible principles
2. All 4 regression trigger tests pass (diagnose silently, no scoring without intake, no default fundraising, no downstream before upstream)
3. buildSystemPrompt, getPromptForTopic, getFredGreeting, buildTopicPrompt, and buildStepGuidanceBlock all have passing tests
4. buildFounderContext has passing tests for all major states (empty, partial, full, first-conversation, errors)
5. Full test suite (`npx vitest run`) passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/34-system-prompt-overhaul/34-03-SUMMARY.md`
</output>
